--- 
title: Números de Coma Flotante
description: Explicación de cómo funcionan los números de coma flotante y para qué son útiles
---

Por qué son necesarios los números de coma flotante
---------------------------------------------------

Como la memoria de los ordenadores es limitada, no puedes almacenar números
con precisión infinita, no importa si usas [fracciones binarias](/formats/binary/) o
decimales: en algún punto tienes que cortar. Pero ¿cuánta precisión se necesita?
¿Y *dónde* se necesita? ¿Cuántos dígitos enteros y cuántos fraccionarios?

* Para un ingeniero construyendo una autopista, no importa si tiene 10 metros o 10.0001 metros de ancho - posiblemente ni siquiera sus mediciones eran así de precisas.
* Para alguien diseñando un microchip, 0.0001 metros (la décima parte de un milímetro) es una diferencia *enorme* - pero nunca tendrá que manejar distancias mayores de 0.1 metros.
* Un físico necesita usar la [velocidad de la luz](http://es.wikipedia.org/wiki/Velocidad_de_la_luz) (más o menos 300000000) y la [constante de gravitación universal](http://es.wikipedia.org/wiki/Constante_de_gravitaci%C3%B3n_universal) (más o menos 0.0000000000667) juntas en el mismo cálculo.

Para satisfacer al ingeniero y al diseñador de circuitos integrados, el formato
tiene que ser preciso para números de órdenes de magnitud muy diferentes. Sin
embargo, solo se necesita precisión *relativa*. Para satisfacer al físico, debe
ser posible hacer cálculos que involucren números de órdenes muy dispares.

Básicamente, tener un número fijo de dígitos enteros y fraccionarios no es útil - y la solución es un formato con una *coma flotante*.

How floating-point numbers work
-------------------------------
The idea is to compose a number of two main parts:

* A **significand** that contains the number's digits. Negative significands represent negative numbers.
* An **exponent** that says where the decimal (or binary) point is placed relative to the beginning of the significand. Negative exponents represent numbers that are very small (i.e. close to zero).

Such a format satisfies all the requirements:

* It can represent numbers at wildly different magnitudes (limited by the length of the exponent)
* It provides the same relative accuracy at all magnitudes (limited by the length of the significand)
* It allows calculations across magnitudes: multiplying a very large and a very small number preserves the accuracy of both in the result.

Decimal floating-point numbers usually take the form of [scientific notation](http://en.wikipedia.org/wiki/Scientific_notation) with an
explicit point always between the 1st and 2nd digits. The exponent is
either written explicitly including the base, or an **e** is used to
separate it from the significand.

| Significand | Exponent | Scientific notation | Fixed-point value |
|-------------|----------|---------------------|-------------------|
| 1.5 | 4 | 1.5 &sdot; 10<sup>4</sup> | 15000 |
| -2.001 | 2 | -2.001 &sdot; 10<sup>2</sup> | -200.1 |
| 5 | -3 |  5 &sdot; 10<sup>-3</sup> | 0,005 | 
| 6.667 | -11 | 6.667e-11 | 0.0000000000667 |

The standard
------------
Nearly all hardware and programming languages use floating-point numbers in the same binary formats, which are defined in the [IEEE 754](http://en.wikipedia.org/wiki/IEEE_754-2008) standard. The usual formats are 32 or 64 bits in total length:

| Format | Total bits | Significand bits | Exponent bits | Smallest number | Largest number |
|--------|------------|------------------|---------------|-----------------|----------------|
| Single precision | 32 | 23 + 1 sign | 8  | ca. 1.2 &sdot; 10<sup>-38</sup> | ca. 3.4 &sdot; 10<sup>38</sup>|
| Double precision | 64 | 52 + 1 sign | 11 | ca. 5.0 &sdot; 10<sup>-324</sup> | ca. 1.8 &sdot; 10<sup>308</sup> |

Note that there are some peculiarities:

* The **actual bit sequence** is the sign bit first, followed by the exponent and finally the significand bits.
* The exponent does not have a sign; instead an **exponent bias** is subtracted from it (127 for single and 1023 for double precision). This, and the bit sequence, allows floating-point numbers to be compared and sorted correctly even when interpreting them as integers.
* The significand's most significant bit is assumed to be 1 and omitted, except for special cases.
* There are separate **positive and a negative zero** values, differing in the sign bit, where all other bits are 0. These must be considered equal even though their bit patterns are different.
* There are special **positive and negative infinity** values, where the exponent is all 1-bits and the significand is all 0-bits. These are the results of calculations where the positive range of the exponent is exceeded, or division  of a regular number by zero.
* There are special **not a number** (or NaN) values where the exponent is all 1-bits and the significand is *not* all 0-bits. These represent the result of various undefined calculations (like multiplying 0 and infinity, any calculation involving a NaN value, or application-specific cases). Even bit-identical NaN values must *not* be considered equal.